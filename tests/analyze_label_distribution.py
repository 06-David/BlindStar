#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡ç­¾åˆ†å¸ƒåˆ†æè„šæœ¬
ç”¨äºç»Ÿè®¡è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸­å„ç±»åˆ«çš„æ ·æœ¬åˆ†å¸ƒæƒ…å†µ
é‡ç‚¹åˆ†æpersonå’Œcarç±»åˆ«çš„æ ·æœ¬æ•°é‡
"""

import os
from collections import defaultdict
from pathlib import Path
import matplotlib.pyplot as plt
from tqdm import tqdm

# obstacle.yamlä¸­çš„ç±»åˆ«æ˜ å°„
class_names = {
    0: 'person',
    1: 'bicycle',
    2: 'car',
    3: 'traffic_cone',
    4: 'barrier',
    5: 'curb',
    6: 'manhole',
    7: 'stairs',
    8: 'railing',
    9: 'pole',
    10: 'water',
    11: 'sand',
    12: 'snow',
    13: 'tripod',
    14: 'barrel',
    15: 'motorcycle',
    16: 'bus',
    17: 'train',
    18: 'truck',
    19: 'traffic_light',
    20: 'fire_hydrant',
    21: 'stop_sign',
    22: 'bench',
    23: 'chair',
    24: 'red_light',
    25: 'yellow_light',
    26: 'green_light',
    27: 'off_light',
    28: 'crosswalk',
    29: 'guide_arrows'
}

def analyze_labels(labels_dir):
    """åˆ†ææ ‡ç­¾ç›®å½•ä¸­çš„ç±»åˆ«åˆ†å¸ƒ"""
    print(f"åˆ†ææ ‡ç­¾ç›®å½•: {labels_dir}")
    
    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
    class_counts = defaultdict(int)
    total_annotations = 0
    total_files = 0
    
    # è·å–æ‰€æœ‰txtæ–‡ä»¶
    label_files = list(Path(labels_dir).glob("*.txt"))
    
    if not label_files:
        print(f"âŒ æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶åœ¨ {labels_dir}")
        return class_counts, total_annotations, total_files
    
    print(f"æ‰¾åˆ° {len(label_files)} ä¸ªæ ‡ç­¾æ–‡ä»¶")
    
    for label_file in tqdm(label_files, desc="å¤„ç†æ ‡ç­¾æ–‡ä»¶"):
        total_files += 1
        
        if label_file.stat().st_size == 0:
            # ç©ºæ–‡ä»¶è¡¨ç¤ºæ— æ ‡æ³¨å¯¹è±¡
            continue
            
        with open(label_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                    
                # è§£æYOLOæ ¼å¼: class_id x_center y_center width height
                parts = line.split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    class_counts[class_id] += 1
                    total_annotations += 1
    
    return class_counts, total_annotations, total_files

def print_distribution_report(train_counts, val_counts, train_total, val_total, train_files, val_files):
    """æ‰“å°åˆ†å¸ƒæŠ¥å‘Š"""
    print("\n" + "="*60)
    print("æ ‡ç­¾åˆ†å¸ƒåˆ†ææŠ¥å‘Š")
    print("="*60)
    
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"è®­ç»ƒé›†æ–‡ä»¶æ•°: {train_files}")
    print(f"éªŒè¯é›†æ–‡ä»¶æ•°: {val_files}")
    print(f"è®­ç»ƒé›†æ ‡æ³¨æ•°: {train_total}")
    print(f"éªŒè¯é›†æ ‡æ³¨æ•°: {val_total}")
    
    # åˆå¹¶ç»Ÿè®¡
    all_classes = set(train_counts.keys()) | set(val_counts.keys())
    
    print(f"\nğŸ“‹ å„ç±»åˆ«åˆ†å¸ƒ:")
    print(f"{'ç±»åˆ«ID':<8} {'ç±»åˆ«åç§°':<15} {'è®­ç»ƒé›†':<8} {'éªŒè¯é›†':<8} {'æ€»è®¡':<8} {'ç™¾åˆ†æ¯”':<8}")
    print("-" * 70)
    
    # æŒ‰æ€»æ•°æ’åº
    class_totals = []
    for class_id in all_classes:
        train_count = train_counts.get(class_id, 0)
        val_count = val_counts.get(class_id, 0)
        total_count = train_count + val_count
        class_totals.append((class_id, total_count, train_count, val_count))
    
    class_totals.sort(key=lambda x: x[1], reverse=True)
    
    grand_total = train_total + val_total
    
    for class_id, total_count, train_count, val_count in class_totals:
        class_name = class_names.get(class_id, f"unknown_{class_id}")
        percentage = (total_count / grand_total) * 100 if grand_total > 0 else 0
        
        print(f"{class_id:<8} {class_name:<15} {train_count:<8} {val_count:<8} {total_count:<8} {percentage:.2f}%")
    
    # é‡ç‚¹å…³æ³¨personå’Œcar
    print(f"\nğŸ” å…³é”®ç±»åˆ«åˆ†æ:")
    person_train = train_counts.get(0, 0)
    person_val = val_counts.get(0, 0)
    person_total = person_train + person_val
    
    car_train = train_counts.get(2, 0)
    car_val = val_counts.get(2, 0)
    car_total = car_train + car_val
    
    print(f"Person (ç±»åˆ«0):")
    print(f"  - è®­ç»ƒé›†: {person_train} ä¸ªæ ·æœ¬")
    print(f"  - éªŒè¯é›†: {person_val} ä¸ªæ ·æœ¬")
    print(f"  - æ€»è®¡: {person_total} ä¸ªæ ·æœ¬ ({(person_total/grand_total)*100:.2f}%)")
    
    print(f"\nCar (ç±»åˆ«2):")
    print(f"  - è®­ç»ƒé›†: {car_train} ä¸ªæ ·æœ¬")
    print(f"  - éªŒè¯é›†: {car_val} ä¸ªæ ·æœ¬")
    print(f"  - æ€»è®¡: {car_total} ä¸ªæ ·æœ¬ ({(car_total/grand_total)*100:.2f}%)")
    
    # é—®é¢˜è¯Šæ–­
    print(f"\nğŸ”§ é—®é¢˜è¯Šæ–­:")
    if person_total == 0:
        print("âŒ Personç±»åˆ«æ ·æœ¬æ•°ä¸º0ï¼è¿™æ˜¯è¯†åˆ«ä¸åˆ°äººçš„ä¸»è¦åŸå› ã€‚")
    elif person_total < 100:
        print(f"âš ï¸  Personç±»åˆ«æ ·æœ¬æ•°è¿‡å°‘({person_total})ï¼Œå¯èƒ½å¯¼è‡´è¯†åˆ«æ•ˆæœå·®ã€‚")
    
    if car_total == 0:
        print("âŒ Carç±»åˆ«æ ·æœ¬æ•°ä¸º0ï¼è¿™æ˜¯è¯†åˆ«ä¸åˆ°æ±½è½¦çš„ä¸»è¦åŸå› ã€‚")
    elif car_total < 100:
        print(f"âš ï¸  Carç±»åˆ«æ ·æœ¬æ•°è¿‡å°‘({car_total})ï¼Œå¯èƒ½å¯¼è‡´è¯†åˆ«æ•ˆæœå·®ã€‚")

def main():
    """ä¸»å‡½æ•°"""
    print("BlindStar æ ‡ç­¾åˆ†å¸ƒåˆ†æ")
    print("=" * 30)
    
    # æ•°æ®é›†è·¯å¾„
    dataset_root = Path("e:/BlindStar/datasets")
    train_labels_dir = dataset_root / "labels" / "train"
    val_labels_dir = dataset_root / "labels" / "val"
    
    # æ£€æŸ¥è·¯å¾„å­˜åœ¨æ€§
    if not train_labels_dir.exists():
        print(f"âŒ è®­ç»ƒæ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {train_labels_dir}")
        return
    
    if not val_labels_dir.exists():
        print(f"âŒ éªŒè¯æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨: {val_labels_dir}")
        return
    
    # åˆ†æè®­ç»ƒé›†
    print("\nğŸ“ åˆ†æè®­ç»ƒé›†...")
    train_counts, train_total, train_files = analyze_labels(train_labels_dir)
    
    # åˆ†æéªŒè¯é›†
    print("\nğŸ“ åˆ†æéªŒè¯é›†...")
    val_counts, val_total, val_files = analyze_labels(val_labels_dir)
    
    # ç”ŸæˆæŠ¥å‘Š
    print_distribution_report(train_counts, val_counts, train_total, val_total, train_files, val_files)

if __name__ == "__main__":
    main()
