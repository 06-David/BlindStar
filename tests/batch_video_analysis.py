#!/usr/bin/env python3
r"""
æ‰¹é‡è§†é¢‘å¸§åˆ†æå·¥å…·
ä»æœ¬åœ°æ–‡ä»¶å¤¹è¯»å–è§†é¢‘æ–‡ä»¶å¹¶ç”Ÿæˆå¸§åˆ†ææ•°æ®

é»˜è®¤é…ç½®:
- è¾“å…¥ç›®å½•: C:\MyCode\AI\BlindStar\input_videos
- è¾“å‡ºç›®å½•: C:\MyCode\AI\BlindStar\analyze_videos
- åˆ†ææ—¥å¿—ç›®å½•: C:\MyCode\AI\BlindStar\analyze_videos

ä½¿ç”¨æ–¹æ³•:
1. ç›´æ¥è¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰:
   python batch_video_analysis.py

2. æŒ‡å®šè¾“å…¥ç›®å½•:
   python batch_video_analysis.py "your_input_folder"

3. å®Œå…¨è‡ªå®šä¹‰:
   python batch_video_analysis.py "input" --output-dir "output" --analysis-dir "logs"
"""

import os
import sys
import argparse
import logging

# Add project root to Python path to allow running from any directory
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(script_dir, '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from pathlib import Path
from typing import List, Optional
import time

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BatchVideoAnalyzer:
    """
    æ‰¹é‡è§†é¢‘åˆ†æå™¨
    """
    
    def __init__(self, 
                 input_dir: str,
                 output_dir: str | None = None,
                 analysis_log_dir: str | None = None,
                 model_weights: str | None = None,
                 data_yaml: str | None = None,
                 conf: float = 0.25):
        """
        åˆå§‹åŒ–æ‰¹é‡è§†é¢‘åˆ†æå™¨
        
        Args:
            input_dir: è¾“å…¥è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
            output_dir: è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
            analysis_log_dir: å¸§åˆ†ææ—¥å¿—æ–‡ä»¶å¤¹è·¯å¾„
        """
        self.input_dir = Path(input_dir)
        
        # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºç›®å½•åç§°
        ts = time.strftime("%Y%m%d_%H%M%S")
        input_folder_name = self.input_dir.name
        
        if output_dir is None:
            self.output_dir = Path("logs") / f"{input_folder_name}_{ts}"
        else:
            self.output_dir = Path(output_dir)
            
        if analysis_log_dir is None:
            self.analysis_log_dir = Path("logs") / f"{input_folder_name}_{ts}"
        else:
            self.analysis_log_dir = Path(analysis_log_dir)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.analysis_log_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”¯æŒçš„è§†é¢‘æ ¼å¼
        self.supported_formats = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}
        
        # å‚æ•°
        self.model_weights = model_weights
        self.data_yaml = data_yaml
        self.confidence_threshold = conf

        # åˆå§‹åŒ–ç»„ä»¶
        self.detector = None
        self.distance_calc = None
        self.speed_calc = None
        self.video_processor = None
        
        logger.info(f"æ‰¹é‡è§†é¢‘åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  è¾“å…¥ç›®å½•: {self.input_dir}")
        logger.info(f"  è¾“å‡ºç›®å½•: {self.output_dir}")
        logger.info(f"  åˆ†ææ—¥å¿—ç›®å½•: {self.analysis_log_dir}")
    
    def initialize_components(self):
        """åˆå§‹åŒ–æ£€æµ‹å’Œåˆ†æç»„ä»¶"""
        logger.info("åˆå§‹åŒ–æ£€æµ‹å’Œåˆ†æç»„ä»¶...")
        
        try:
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            from core.detector import YOLOv8Detector
            self.detector = YOLOv8Detector(
                model_variant=self.model_weights or 'small',
                confidence_threshold=self.confidence_threshold,
                data_yaml=self.data_yaml)
            logger.info("âœ… YOLOæ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–è·ç¦»è®¡ç®—å™¨
            from core.distance import DistanceMeasurement
            self.distance_calc = DistanceMeasurement()
            logger.info("âœ… è·ç¦»è®¡ç®—å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–é€Ÿåº¦è®¡ç®—å™¨
            try:
                from core.speed_measurement import OpticalFlowSpeedMeasurement
                self.speed_calc = OpticalFlowSpeedMeasurement()
                logger.info("âœ… é€Ÿåº¦è®¡ç®—å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸  é€Ÿåº¦è®¡ç®—å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.speed_calc = None
            
            # åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
            from core.video_processor import VideoProcessor
            self.video_processor = VideoProcessor(
                detector=self.detector,
                distance_calculator=self.distance_calc,
                speed_calculator=self.speed_calc,
                frame_skip=1,
                output_fps=30
            )
            logger.info("âœ… è§†é¢‘å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def find_video_files(self) -> List[Path]:
        """æŸ¥æ‰¾è¾“å…¥ç›®å½•ä¸­çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
        logger.info(f"æœç´¢è§†é¢‘æ–‡ä»¶: {self.input_dir}")
        
        video_files = []
        
        if not self.input_dir.exists():
            logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.input_dir}")
            return video_files
        
        # é€’å½’æœç´¢è§†é¢‘æ–‡ä»¶
        for file_path in self.input_dir.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in self.supported_formats:
                video_files.append(file_path)
        
        logger.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
        for video_file in video_files:
            logger.info(f"  - {video_file.name}")
        
        return video_files
    
    def process_single_video(self, 
                           video_path: Path, 
                           max_duration: Optional[float] = None) -> bool:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            max_duration: æœ€å¤§å¤„ç†æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        if not self.video_processor:
            logger.error("âŒ Video processor not initialized. Cannot process video.")
            return False

        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path.name}")
        
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_filename = f"analyzed_{timestamp}_{video_path.stem}.mp4"
            output_path = self.output_dir / output_filename
            
            # å¤„ç†è§†é¢‘ï¼ˆä½¿ç”¨å¸§åˆ†æåŠŸèƒ½ï¼‰
            start_time = time.time()
            stats = self.video_processor.process_video_file_with_frame_analysis(
                str(video_path),
                str(output_path),
                max_duration=max_duration,
                frame_analysis_config={
                    "log_dir": str(self.analysis_log_dir),
                    "enable_json_log": True,
                    "enable_csv_log": True,
                    "enable_detailed_log": True,
                    "log_level": "INFO"
                }
            )
            processing_time = time.time() - start_time
            
            # è¾“å‡ºå¤„ç†ç»“æœ
            logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ: {video_path.name}")
            logger.info(f"   è¾“å‡ºæ–‡ä»¶: {output_filename}")
            logger.info(f"   å¤„ç†å¸§æ•°: {stats.processed_frames}")
            logger.info(f"   æ£€æµ‹æ€»æ•°: {stats.total_detections}")
            logger.info(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}s")
            logger.info(f"   å¹³å‡FPS: {stats.average_fps:.2f}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è§†é¢‘å¤±è´¥ {video_path.name}: {e}")
            return False
    
    def process_all_videos(self, max_duration: Optional[float] = None) -> dict:
        """
        å¤„ç†æ‰€æœ‰è§†é¢‘æ–‡ä»¶
        
        Args:
            max_duration: æ¯ä¸ªè§†é¢‘çš„æœ€å¤§å¤„ç†æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            dict: å¤„ç†ç»“æœç»Ÿè®¡
        """
        logger.info("å¼€å§‹æ‰¹é‡å¤„ç†è§†é¢‘...")

        video_files = self.find_video_files()
        if not video_files:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return {"total": 0, "success": 0, "failed": 0}

        # å¤„ç†ç»Ÿè®¡
        total_files = len(video_files)
        success_count = 0
        failed_count = 0
        
        # é€ä¸ªå¤„ç†è§†é¢‘
        for video_path in video_files:
            logger.info(f"\n{'='*80}")
            logger.info(f"å¤„ç†è§†é¢‘: {video_path.name}")
            logger.info(f"{'='*80}")
            if self.process_single_video(video_path, max_duration):
                success_count += 1
            else:
                failed_count += 1
        
        # è¾“å‡ºæ€»ç»“
        logger.info("\n" + "=" * 60)
        logger.info("æ‰¹é‡å¤„ç†å®Œæˆ!")
        logger.info(f"  æ€»æ–‡ä»¶æ•°: {total_files}")
        logger.info(f"  æˆåŠŸå¤„ç†: {success_count}")
        logger.info(f"  å¤„ç†å¤±è´¥: {failed_count}")
        logger.info(f"  æˆåŠŸç‡: {success_count/total_files*100:.1f}%")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„åˆ†ææ–‡ä»¶
        self.show_analysis_files()
        
        return {
            "total": total_files,
            "success": success_count,
            "failed": failed_count
        }
    
    def show_analysis_files(self):
        """æ˜¾ç¤ºç”Ÿæˆçš„å¸§åˆ†ææ–‡ä»¶"""
        logger.info("\nç”Ÿæˆçš„å¸§åˆ†ææ–‡ä»¶:")
        
        if not self.analysis_log_dir.exists():
            logger.warning("âš ï¸  åˆ†ææ—¥å¿—ç›®å½•ä¸å­˜åœ¨")
            return
        
        # æŸ¥æ‰¾åˆ†ææ–‡ä»¶
        json_files = list(self.analysis_log_dir.glob("frame_analysis_*.json"))
        csv_files = list(self.analysis_log_dir.glob("frame_analysis_*.csv"))
        log_files = list(self.analysis_log_dir.glob("detailed_analysis_*.log"))
        
        logger.info(f"  JSONæ–‡ä»¶: {len(json_files)}")
        logger.info(f"  CSVæ–‡ä»¶: {len(csv_files)}")
        logger.info(f"  è¯¦ç»†æ—¥å¿—: {len(log_files)}")
        
        # æ˜¾ç¤ºæœ€æ–°çš„å‡ ä¸ªæ–‡ä»¶
        if json_files:
            latest_json = max(json_files, key=lambda x: x.stat().st_mtime)
            logger.info(f"  æœ€æ–°JSON: {latest_json.name}")
        
        if csv_files:
            latest_csv = max(csv_files, key=lambda x: x.stat().st_mtime)
            logger.info(f"  æœ€æ–°CSV: {latest_csv.name}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡è§†é¢‘å¸§åˆ†æå·¥å…·')
    parser.add_argument('input_dir', nargs='?',
                       default=r'C:\MyCode\AI\BlindStar\input_videos',
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„ (é»˜è®¤: C:\\MyCode\\AI\\BlindStar\\input_videos)')
    parser.add_argument('--output-dir', default=None,
                       help='è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆ)')
    parser.add_argument('--analysis-dir', default=None,
                       help='å¸§åˆ†ææ—¥å¿—æ–‡ä»¶å¤¹è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆ)')
    parser.add_argument('--max-duration', type=float, default=None,
                       help='æ¯ä¸ªè§†é¢‘çš„æœ€å¤§å¤„ç†æ—¶é•¿ï¼ˆç§’ï¼‰')
    parser.add_argument('--input-size', default='384,512', help='æ·±åº¦æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼Œä¾‹å¦‚384,512')
    parser.add_argument('--max-videos', type=int, default=None, help='æœ€å¤šå¤„ç†è§†é¢‘æ•°é‡')
    parser.add_argument('--parallel', action='store_true', help='æ˜¯å¦å¹¶è¡Œå¤„ç†è§†é¢‘')
    parser.add_argument('--workers', type=int, default=1, help='å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°')
    parser.add_argument('--recursive', action='store_true', help='é€’å½’æŸ¥æ‰¾è§†é¢‘')
    parser.add_argument('--weights', default=None,
                       help='è‡ªå®šä¹‰æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: å®˜æ–¹yolov8s.ptï¼‰')
    parser.add_argument('--data', dest='data_yaml', default=None,
                       help='è‡ªå®šä¹‰æ•°æ®é›† YAMLï¼ˆå« namesï¼‰æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤0.25)')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')

    args = parser.parse_args()

    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    logger.info("ğŸš€ æ‰¹é‡è§†é¢‘å¸§åˆ†æå·¥å…·å¯åŠ¨")
    logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {args.input_dir}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    logger.info(f"ğŸ“ åˆ†ææ—¥å¿—ç›®å½•: {args.analysis_dir}")

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.info("ğŸ” è¯¦ç»†æ—¥å¿—æ¨¡å¼å·²å¯ç”¨")

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not Path(args.input_dir).exists():
        logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        logger.info(f"ğŸ’¡ è¯·ç¡®ä¿ç›®å½•å­˜åœ¨æˆ–åˆ›å»ºç›®å½•: {args.input_dir}")
        logger.info(f"ğŸ’¡ æ‚¨å¯ä»¥æ‰‹åŠ¨åˆ›å»ºç›®å½•å¹¶æ”¾å…¥è§†é¢‘æ–‡ä»¶ï¼Œç„¶åé‡æ–°è¿è¡Œç¨‹åº")
        return 1

    # åˆ›å»ºæ‰¹é‡åˆ†æå™¨
    analyzer = BatchVideoAnalyzer(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        analysis_log_dir=args.analysis_dir,
        model_weights=args.weights,
        data_yaml=args.data_yaml,
        conf=args.conf
    )
    
    # åˆå§‹åŒ–ç»„ä»¶
    if not analyzer.initialize_components():
        logger.error("âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥")
        return 1
    
    import json
    import datetime
    import time as _time
    # ç»Ÿè®¡ä¿¡æ¯
    batch_start = _time.time()
    results = analyzer.process_all_videos(max_duration=args.max_duration)
    batch_end = _time.time()
    # è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†jsonæŠ¥å‘Š
    report = {
        'timestamp': datetime.datetime.now().isoformat(),
        'summary': {
            'total_files': results.get('total', 0),
            'successful_files': results.get('success', 0),
            'failed_files': results.get('failed', 0),
            'success_rate': (results.get('success', 0) / results.get('total', 1) * 100) if results.get('total', 0) > 0 else 0,
            'total_processing_time': batch_end - batch_start
        },
        'results': results,
        'errors': []
    }
    ts = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    json_report_path = Path(args.analysis_dir) / f"batch_video_report_{ts}.json"
    with open(json_report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False, default=str)
    logger.info(f"ğŸ“ è¯¦ç»†JSONæŠ¥å‘Š: {json_report_path}")
    # è¿”å›ç»“æœ
    if results["failed"] == 0:
        logger.info("ğŸ‰ æ‰€æœ‰è§†é¢‘å¤„ç†æˆåŠŸ!")
        return 0
    else:
        logger.warning(f"âš ï¸  {results['failed']} ä¸ªè§†é¢‘å¤„ç†å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit(main())
