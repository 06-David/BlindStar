#!/usr/bin/env python3
"""batch_image_analysis.py

æ‰¹é‡å›¾ç‰‡æ£€æµ‹è„šæœ¬ï¼ˆWindows cmd å‹å¥½ï¼‰ã€‚

åŠŸèƒ½ï¼š
1. é€’å½’æ‰«æè¾“å…¥ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡ï¼ˆjpgã€jpegã€pngã€bmpã€webpï¼‰ã€‚
2. ä½¿ç”¨ `core.detector.YOLOv8Detector` å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
3. å°†å¸¦æ¡†ç»“æœä¿å­˜åˆ°è¾“å‡ºç›®å½•ï¼Œæ–‡ä»¶åä¿æŒä¸€è‡´ã€‚
4. ç”Ÿæˆä¸€ä¸ª `summary.csv`ï¼šimage_path, num_detections, æ¯ä¸ªæ£€æµ‹çš„ class/confã€‚
5. å¯é€‰ç”ŸæˆåŒ…å«æ·±åº¦ä¿¡æ¯çš„ç»„åˆå›¾ç‰‡ã€‚

å‘½ä»¤è¡Œç¤ºä¾‹ï¼š
    python batch_image_analysis.py C:\Images \
           --output C:\DetectOut \
           --weights runs/detect/train/weights/best.pt \
           --data data.yaml \
           --conf 0.3 \
           --with-depth
"""
from __future__ import annotations
import sys
import os

# Add project root to Python path to allow running from any directory
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(script_dir, '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import argparse
import csv
import logging
from pathlib import Path
from typing import List
import shutil
import cv2
from tqdm import tqdm
import time

from core.detector import YOLOv8Detector, draw_detections
from core.depth_visualizer import DepthVisualizer

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(levelname)s - %(message)s")

SUPPORTED_IMG_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

def find_images(root: Path) -> List[Path]:
    """Recursively list image files under root."""
    images: List[Path] = []
    for p in root.rglob('*'):
        if p.is_file() and p.suffix.lower() in SUPPORTED_IMG_EXTS:
            images.append(p)
    return images


import json
import traceback
import datetime

def analyze_images(input_dir: Path,
                   batch_dir: Path,
                   detector: YOLOv8Detector,
                   input_size=(384,512),
                   max_images=None,
                   parallel=False,
                   workers=1,
                   recursive=False) -> None:
    """
    æ‰¹é‡å¤„ç†å›¾ç‰‡ï¼Œä¾æ¬¡æ‰§è¡Œï¼š
    1. ç›®æ ‡æ£€æµ‹ä¸æ£€æµ‹æ¡†ä¿å­˜
    2. æ·±åº¦ä¼ªå½©è‰²å›¾ç”Ÿæˆ
    3. æ£€æµ‹æ¡†æ·±åº¦æ•°å€¼æ ‡æ³¨
    4. æ·±åº¦ä¿¡æ¯ä¸æ£€æµ‹æ¡†èåˆ
    è¾“å‡ºåˆ°originals/yolo/depth/combinedå››ä¸ªå­ç›®å½•ï¼Œç»Ÿè®¡ä¿¡æ¯å†™å…¥summary.csvã€‚
    """
    # é€’å½’æŸ¥æ‰¾å›¾ç‰‡
    images = find_images(input_dir) if recursive else list(input_dir.glob('*'))
    images = [p for p in images if p.is_file() and p.suffix.lower() in SUPPORTED_IMG_EXTS]
    if max_images:
        images = images[:max_images]
    if not images:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
        return

    originals_dir = batch_dir / 'originals'  # åŸå›¾
    yolo_dir = batch_dir / 'yolo'            # æ£€æµ‹æ¡†+æ·±åº¦æ•°å€¼
    depth_dir = batch_dir / 'depth'          # æ·±åº¦ä¼ªå½©è‰²
    combined_dir = batch_dir / 'combined'    # æ£€æµ‹ä¸æ·±åº¦èåˆ

    originals_dir.mkdir(parents=True, exist_ok=True)
    yolo_dir.mkdir(parents=True, exist_ok=True)
    depth_dir.mkdir(parents=True, exist_ok=True)
    combined_dir.mkdir(parents=True, exist_ok=True)

    summary_path = batch_dir / 'summary.csv'

    # åˆå§‹åŒ–æ·±åº¦å¯è§†åŒ–å™¨å’Œè·ç¦»æµ‹é‡å™¨
    depth_vis = DepthVisualizer(device='auto')
    from core.distance import ZoeDepthDistanceMeasurement
    distance_calc = ZoeDepthDistanceMeasurement(device='auto')

    # ç»Ÿè®¡ä¿¡æ¯
    start_time = time.time()
    total_files = len(images)
    successful_files = 0
    failed_files = 0
    error_files = []
    results = []

    with summary_path.open('w', newline='', encoding='utf-8') as csv_f:
        writer = csv.writer(csv_f)
        writer.writerow(['image', 'num_detections', 'detections', 'distances'])

        for img_path in tqdm(images, ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]', desc='æ‰¹é‡å›¾ç‰‡æ£€æµ‹', unit='file'):
            try:
                img = cv2.imread(str(img_path))
                if img is None:
                    logger.warning(f"âš ï¸  è¯»å–å¤±è´¥: {img_path}")
                    failed_files += 1
                    error_files.append(str(img_path))
                    continue

                # ------ 1. ç›®æ ‡æ£€æµ‹ ------
                detections = detector.detect(img)

                # ------ 2. æ·±åº¦æ•°å€¼è®¡ç®— ------
                depth_infos = distance_calc.calculate_distances_batch(img, detections) if detections else []
                for detection, depth_info in zip(detections, depth_infos):
                    detection.distance = float(depth_info.distance_meters) if depth_info.distance_meters is not None else None

                # ------ 3. æ£€æµ‹æ¡†+æ·±åº¦æ•°å€¼å›¾ ------
                annotated = draw_detections(img, detections, show_distance=True)

                # ------ 4. æ·±åº¦ä¼ªå½©è‰²å›¾ ------
                depth_color = depth_vis.get_colormap(img)

                # ------ 5. æ£€æµ‹ä¸æ·±åº¦èåˆ ------
                combined = depth_vis.overlay(annotated, alpha=0.4)

                # ------ 6. ä¿å­˜æ‰€æœ‰ç»“æœ ------
                rel_path = img_path.relative_to(input_dir)
                # ä¿å­˜åŸå›¾
                orig_path = originals_dir / rel_path
                orig_path.parent.mkdir(parents=True, exist_ok=True)
                if not orig_path.exists():
                    shutil.copy2(str(img_path), str(orig_path))
                # æ£€æµ‹æ¡†+æ·±åº¦æ•°å€¼
                yolo_path = yolo_dir / rel_path
                yolo_path.parent.mkdir(parents=True, exist_ok=True)
                cv2.imwrite(str(yolo_path), annotated)
                # æ·±åº¦ä¼ªå½©è‰²
                depth_path = depth_dir / rel_path
                depth_path.parent.mkdir(parents=True, exist_ok=True)
                cv2.imwrite(str(depth_path), depth_color)
                # æ£€æµ‹ä¸æ·±åº¦èåˆ
                combined_path = combined_dir / rel_path
                combined_path.parent.mkdir(parents=True, exist_ok=True)
                cv2.imwrite(str(combined_path), combined)

                # ------ 7. å†™å…¥CSVç»Ÿè®¡ ------
                det_summary = '; '.join([f"{d.class_name}:{d.confidence:.2f}" for d in detections])
                dist_summary = '; '.join([f"{d.distance:.2f}m" if hasattr(d, 'distance') and d.distance is not None else "N/A" for d in detections])
                writer.writerow([str(img_path), len(detections), det_summary, dist_summary])

                # è®°å½•ç»“æœ
                results.append({
                    'image': str(img_path),
                    'num_detections': len(detections),
                    'detections': det_summary,
                    'distances': dist_summary
                })
                successful_files += 1
            except Exception as ex:
                failed_files += 1
                error_files.append(str(img_path))
                logger.error(f"âŒ å¤„ç†å¤±è´¥: {img_path}, é”™è¯¯: {ex}\n{traceback.format_exc()}")

    elapsed = time.time() - start_time
    # è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†jsonæŠ¥å‘Š
    report = {
        'timestamp': datetime.datetime.now().isoformat(),
        'summary': {
            'total_files': total_files,
            'successful_files': successful_files,
            'failed_files': failed_files,
            'success_rate': (successful_files / total_files * 100) if total_files > 0 else 0,
            'total_processing_time': elapsed
        },
        'results': results,
        'errors': error_files
    }
    json_report_path = batch_dir / f"batch_image_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(json_report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False, default=str)
    logger.info(f"âœ… å®Œæˆï¼Œå¤„ç† {len(images)} å¼ å›¾ç‰‡ï¼Œç»“æœä¿å­˜åœ¨: {batch_dir}")
    logger.info(f"ğŸ“„ æ±‡æ€» CSV: {summary_path}")
    logger.info(f"ğŸ“ è¯¦ç»†JSONæŠ¥å‘Š: {json_report_path}")


def parse_args():
    parser = argparse.ArgumentParser(description='æ‰¹é‡å›¾ç‰‡æ£€æµ‹')
    parser.add_argument('input_dir', help='è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹')
    parser.add_argument('--weights', default='yolov8s.pt', help='YOLOæƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆ.ptï¼‰')
    parser.add_argument('--data', dest='data_yaml', default=None, help='æ•°æ®é›† YAMLï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--conf', type=float, default=0.25, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--device', default='auto', help='è®¾å¤‡ cpu/cuda (é»˜è®¤è‡ªåŠ¨)')
    parser.add_argument('--input-size', default='384,512', help='æ·±åº¦æ¨¡å‹è¾“å…¥å°ºå¯¸ï¼Œä¾‹å¦‚384,512')
    parser.add_argument('--max-images', type=int, default=None, help='æœ€å¤šå¤„ç†å›¾ç‰‡æ•°é‡')
    parser.add_argument('--parallel', action='store_true', help='æ˜¯å¦å¹¶è¡Œå¤„ç†å›¾ç‰‡')
    parser.add_argument('--workers', type=int, default=1, help='å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°')
    parser.add_argument('--recursive', action='store_true', help='é€’å½’æŸ¥æ‰¾å›¾ç‰‡')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†æ—¥å¿—')
    return parser.parse_args()


def main():
    args = parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    input_dir = Path(args.input_dir)

    # è‡ªåŠ¨ç”Ÿæˆæ‰¹å¤„ç†ç›®å½•
    ts = time.strftime("%Y%m%d_%H%M%S")
    input_folder_name = input_dir.name
    batch_dir = Path("logs") / f"{input_folder_name}_{ts}"

    if not input_dir.exists():
        logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return 1

    logger.info(f"ğŸš€ æ‰¹é‡å›¾ç‰‡æ£€æµ‹å¯åŠ¨")
    logger.info(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {batch_dir}")

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = YOLOv8Detector(
        model_variant=args.weights,
        confidence_threshold=args.conf,
        device=args.device,
        data_yaml=args.data_yaml
    )

    analyze_images(
        input_dir, batch_dir, detector,
        input_size=tuple(map(int, args.input_size.split(','))) if args.input_size else (384,512),
        max_images=args.max_images,
        parallel=args.parallel,
        workers=args.workers,
        recursive=args.recursive
    )
    return 0


if __name__ == '__main__':
    exit(main())