#!/usr/bin/env python3
"""
å®æ—¶è§†é¢‘å†³ç­–åˆ†æå™¨ - BlindStaræ ¸å¿ƒç»„ä»¶
é›†æˆYOLOæ£€æµ‹ã€æ·±åº¦ä¼°è®¡å’Œå†³ç­–ç³»ç»Ÿï¼Œæä¾›å®æ—¶è§†é¢‘æµåˆ†æå’Œè¯­éŸ³æ’­æŠ¥
"""

import cv2
import numpy as np
import time
import threading
import logging
from typing import Optional, Callable, Dict, Any, List, Tuple
from dataclasses import dataclass
from pathlib import Path
import queue
from collections import deque

from .detector import YOLOv8Detector, DetectionResult
from .distance import ZoeDepthDistanceMeasurement
from .decision_engine import DecisionEngine, create_decision_context
from .tts_engine import TTSEngine
from .navigation_context import NavigationContextManager, NavigationMode, GPSLocation

logger = logging.getLogger(__name__)


@dataclass
class FrameAnalysisResult:
    """å•å¸§åˆ†æç»“æœ"""
    frame_id: int
    timestamp: float
    detections: List[Dict[str, Any]]
    depth_map: Optional[np.ndarray]
    decision_output: Optional[Dict[str, Any]]
    navigation_output: Optional[Dict[str, Any]]
    processing_time: float
    fps: float


@dataclass
class VideoAnalysisStats:
    """è§†é¢‘åˆ†æç»Ÿè®¡ä¿¡æ¯"""
    total_frames: int = 0
    processed_frames: int = 0
    dropped_frames: int = 0
    average_fps: float = 0.0
    average_processing_time: float = 0.0
    detection_count: int = 0
    hazard_count: int = 0
    decision_count: int = 0


class RealtimeVideoAnalyzer:
    """å®æ—¶è§†é¢‘å†³ç­–åˆ†æå™¨"""
    
    def __init__(self,
                 yolo_model: str = "small",
                 depth_model: str = "MiDaS_small",
                 confidence_threshold: float = 0.6,
                 enable_depth: bool = True,
                 enable_tts: bool = True,
                 max_fps: float = 15.0,
                 buffer_size: int = 5,
                 enable_navigation: bool = False,
                 nav_mode: str = "assist"):
        """
        åˆå§‹åŒ–å®æ—¶è§†é¢‘åˆ†æå™¨
        
        Args:
            yolo_model: YOLOæ¨¡å‹å¤§å°
            depth_model: æ·±åº¦ä¼°è®¡æ¨¡å‹
            confidence_threshold: æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            enable_depth: æ˜¯å¦å¯ç”¨æ·±åº¦ä¼°è®¡
            enable_tts: æ˜¯å¦å¯ç”¨è¯­éŸ³æ’­æŠ¥
            max_fps: æœ€å¤§å¤„ç†å¸§ç‡
        enable_navigation: æ˜¯å¦å¯ç”¨å¯¼èˆª
        nav_mode: å¯¼èˆªæ¨¡å¼ï¼ˆassist/guide/fullï¼‰
            buffer_size: å¸§ç¼“å†²åŒºå¤§å°
            enable_navigation: æ˜¯å¦å¯ç”¨å¯¼èˆªé›†æˆ
            nav_mode: å¯¼èˆªæ¨¡å¼ï¼ˆassist/guide/fullï¼‰
        """
        self.max_fps = max_fps
        self.frame_interval = 1.0 / max_fps
        self.buffer_size = buffer_size
        self.enable_depth = enable_depth
        self.enable_tts = enable_tts
        self.enable_navigation = enable_navigation
        self.nav_mode = nav_mode
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.detector = None
        self.depth_estimator = None
        self.decision_engine = None
        self.tts_engine = None
        self.nav_context = None
        
        # å­˜å‚¨åˆå§‹åŒ–å‚æ•°
        self.yolo_model = yolo_model
        self.depth_model = depth_model
        self.confidence_threshold = confidence_threshold
        
        # å¤„ç†çŠ¶æ€
        self.is_running = False
        self.is_initialized = False
        
        # å¸§ç¼“å†²å’Œå¤„ç†é˜Ÿåˆ—
        self.frame_queue = queue.Queue(maxsize=buffer_size)
        self.result_queue = queue.Queue(maxsize=buffer_size)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = VideoAnalysisStats()
        self.processing_times = deque(maxlen=100)  # ä¿å­˜æœ€è¿‘100å¸§çš„å¤„ç†æ—¶é—´
        
        # çº¿ç¨‹æ§åˆ¶
        self.processing_thread = None
        self.display_thread = None
        
        # å¯¼èˆªè¯­éŸ³èŠ‚æµ
        self._last_nav_tts_time = 0.0
        self._nav_tts_interval = 5.0
        
        logger.info("âœ… å®æ—¶è§†é¢‘åˆ†æå™¨åˆ›å»ºå®Œæˆ")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            logger.info("ğŸš€ åˆå§‹åŒ–å®æ—¶è§†é¢‘åˆ†æå™¨ç»„ä»¶...")
            
            # åˆå§‹åŒ–YOLOæ£€æµ‹å™¨
            logger.info("åˆå§‹åŒ–YOLOæ£€æµ‹å™¨...")
            self.detector = YOLOv8Detector(
                model_variant=self.yolo_model,
                confidence_threshold=self.confidence_threshold
            )
            
            # åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨
            if self.enable_depth:
                logger.info("åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨...")
                self.depth_estimator = ZoeDepthDistanceMeasurement(
                    model_type=self.depth_model
                )
                self.depth_estimator.ensure_model_loaded()
            
            # åˆå§‹åŒ–å†³ç­–å¼•æ“
            logger.info("åˆå§‹åŒ–å†³ç­–å¼•æ“...")
            self.decision_engine = DecisionEngine(enable_logging=False)
            
            # åˆå§‹åŒ–è¯­éŸ³å¼•æ“
            if self.enable_tts:
                try:
                    logger.info("åˆå§‹åŒ–è¯­éŸ³å¼•æ“...")
                    self.tts_engine = TTSEngine()
                except Exception as e:
                    logger.warning(f"è¯­éŸ³å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
                    self.enable_tts = False
            
            # åˆå§‹åŒ–å¯¼èˆªä¸Šä¸‹æ–‡
            if self.enable_navigation:
                try:
                    mode_map = {
                        "assist": NavigationMode.ASSIST,
                        "guide": NavigationMode.GUIDE,
                        "full": NavigationMode.FULL,
                    }
                    mode_enum = mode_map.get((self.nav_mode or "assist").lower(), NavigationMode.ASSIST)
                    self.nav_context = NavigationContextManager(mode=mode_enum)
                    logger.info(f"åˆå§‹åŒ–å¯¼èˆªä¸Šä¸‹æ–‡: æ¨¡å¼ {mode_enum.value}")
                except Exception as e:
                    logger.warning(f"å¯¼èˆªä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥: {e}")
                    self.enable_navigation = False
            
            self.is_initialized = True
            logger.info("âœ… æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _process_frame(self, frame: np.ndarray, frame_id: int, timestamp: float) -> FrameAnalysisResult:
        """å¤„ç†å•å¸§"""
        start_time = time.time()
        
        # YOLOæ£€æµ‹
        detections = self.detector.detect(frame)
        detection_data = []
        
        for detection in detections:
            det_dict = {
                'class_id': detection.class_id,
                'class_name': detection.class_name,
                'confidence': detection.confidence,
                'bbox': detection.bbox,
                'center': detection.center,
                'area': detection.area
            }
            detection_data.append(det_dict)
        
        # æ·±åº¦ä¼°è®¡
        depth_map = None
        if self.enable_depth and self.depth_estimator:
            try:
                depth_map = self.depth_estimator.predict_depth(frame)
                
                # ä¸ºæ£€æµ‹ç‰©ä½“æ·»åŠ è·ç¦»ä¿¡æ¯
                if detections and depth_map is not None:
                    depth_infos = self.depth_estimator.calculate_distances_batch(frame, detections)
                    for i, (detection, depth_info) in enumerate(zip(detections, depth_infos)):
                        if i < len(detection_data):
                            detection_data[i]['distance_m'] = depth_info.distance_meters
                            detection_data[i]['depth_confidence'] = depth_info.depth_confidence
                            
            except Exception as e:
                logger.warning(f"æ·±åº¦ä¼°è®¡å¤±è´¥: {e}")
        
        # å†³ç­–åˆ†æ
        decision_output = None
        nav_output = None
        try:
            context = create_decision_context(
                frame_id=frame_id,
                detections=detection_data,
                frame_info={
                    'frame_width': frame.shape[1],
                    'frame_height': frame.shape[0],
                    'depth_map': depth_map,
                    'detections': detection_data
                }
            )
            
            decision_result = self.decision_engine.make_decision(context)
            decision_output = decision_result.to_dict()
            
            # è¯­éŸ³æ’­æŠ¥ï¼ˆå¼‚æ­¥ï¼‰
            if (self.enable_tts and self.tts_engine and 
                decision_result.priority >= 3 and  # åªæ’­æŠ¥é‡è¦å†³ç­–
                decision_result.speech):
                
                # å¼‚æ­¥æ’­æŠ¥ï¼Œé¿å…é˜»å¡å¤„ç†
                threading.Thread(
                    target=self._async_speak,
                    args=(decision_result.speech,),
                    daemon=True
                ).start()
            
            # å¯¼èˆªä¿¡æ¯èåˆä¸æ’­æŠ¥ï¼ˆä»…åœ¨å¯ç”¨å¯¼èˆªæ—¶ï¼‰
            if self.enable_navigation and self.nav_context:
                try:
                    nav_instruction = self.nav_context.get_current_instruction()
                    nav_ctx = self.nav_context.get_context()
                    nav_output = {
                        'mode': nav_ctx.navigation_mode.value,
                        'state': nav_ctx.navigation_state.value,
                        'instruction': nav_instruction,
                        'distance_to_destination': nav_ctx.distance_to_destination,
                    }
                    # è‹¥æ— é«˜å±é£é™©ï¼Œé€‚åº¦æ’­æŠ¥å¯¼èˆªæŒ‡ä»¤ï¼ˆèŠ‚æµï¼‰
                    hazard_cnt = 0
                    try:
                        hazard_cnt = (decision_output or {}).get('statistics', {}).get('high_risk_objects', 0)
                    except Exception:
                        hazard_cnt = 0
                    if (self.enable_tts and self.tts_engine and nav_instruction and 
                        hazard_cnt == 0 and
                        (time.time() - self._last_nav_tts_time) >= self._nav_tts_interval):
                        threading.Thread(
                            target=self._async_speak,
                            args=(nav_instruction,),
                            daemon=True
                        ).start()
                        self._last_nav_tts_time = time.time()
                except Exception as e:
                    logger.debug(f"å¯¼èˆªä¿¡æ¯è·å–å¤±è´¥: {e}")
                
        except Exception as e:
            logger.error(f"å†³ç­–åˆ†æå¤±è´¥: {e}")
        
        processing_time = time.time() - start_time
        current_fps = 1.0 / processing_time if processing_time > 0 else 0
        
        return FrameAnalysisResult(
            frame_id=frame_id,
            timestamp=timestamp,
            detections=detection_data,
            depth_map=depth_map,
            decision_output=decision_output,
            navigation_output=nav_output,
            processing_time=processing_time,
            fps=current_fps
        )
    
    def _async_speak(self, text: str):
        """å¼‚æ­¥è¯­éŸ³æ’­æŠ¥"""
        try:
            if self.tts_engine:
                self.tts_engine.speak(text)
        except Exception as e:
            logger.warning(f"è¯­éŸ³æ’­æŠ¥å¤±è´¥: {e}")
    
    def _processing_worker(self):
        """å¤„ç†çº¿ç¨‹å·¥ä½œå‡½æ•°"""
        frame_id = 0
        last_process_time = 0
        
        while self.is_running:
            try:
                # æ§åˆ¶å¤„ç†å¸§ç‡
                current_time = time.time()
                if current_time - last_process_time < self.frame_interval:
                    time.sleep(0.001)  # çŸ­æš‚ä¼‘çœ 
                    continue
                
                # è·å–å¸§
                if self.frame_queue.empty():
                    time.sleep(0.001)
                    continue
                
                frame, timestamp = self.frame_queue.get(timeout=0.1)
                
                # å¤„ç†å¸§
                result = self._process_frame(frame, frame_id, timestamp)
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats.processed_frames += 1
                self.stats.detection_count += len(result.detections)
                if result.decision_output:
                    self.stats.decision_count += 1
                    if result.decision_output.get('high_risk_objects', 0) > 0:
                        self.stats.hazard_count += 1
                
                self.processing_times.append(result.processing_time)
                
                # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
                if not self.result_queue.full():
                    self.result_queue.put(result)
                
                frame_id += 1
                last_process_time = current_time
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†çº¿ç¨‹é”™è¯¯: {e}")
                continue
    
    def _update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if self.processing_times:
            self.stats.average_processing_time = sum(self.processing_times) / len(self.processing_times)
            self.stats.average_fps = 1.0 / self.stats.average_processing_time if self.stats.average_processing_time > 0 else 0
    
    def start_analysis(self, source: str = "0", display_results: bool = True) -> bool:
        """
        å¼€å§‹å®æ—¶åˆ†æ
        
        Args:
            source: è§†é¢‘æºï¼ˆæ‘„åƒå¤´IDæˆ–è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼‰
            display_results: æ˜¯å¦æ˜¾ç¤ºç»“æœçª—å£
            
        Returns:
            æ˜¯å¦æˆåŠŸå¯åŠ¨
        """
        if not self.is_initialized:
            if not self.initialize():
                return False
        
        try:
            # æ‰“å¼€è§†é¢‘æº
            if source.isdigit():
                cap = cv2.VideoCapture(int(source))
            else:
                cap = cv2.VideoCapture(source)
            
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æº: {source}")
                return False
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°ï¼ˆå¦‚æœæ˜¯æ‘„åƒå¤´ï¼‰
            if source.isdigit():
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cap.set(cv2.CAP_PROP_FPS, 30)
            
            logger.info(f"âœ… è§†é¢‘æºå·²æ‰“å¼€: {source}")
            
            # å¯åŠ¨å¤„ç†çº¿ç¨‹
            self.is_running = True
            self.processing_thread = threading.Thread(target=self._processing_worker, daemon=True)
            self.processing_thread.start()
            
            logger.info("ğŸš€ å¼€å§‹å®æ—¶åˆ†æ...")
            
            # ä¸»å¾ªç¯ï¼šè¯»å–å¸§å¹¶æ˜¾ç¤ºç»“æœ
            last_display_time = 0
            display_interval = 1.0 / 30.0  # 30fpsæ˜¾ç¤º
            
            while self.is_running:
                ret, frame = cap.read()
                if not ret:
                    logger.warning("æ— æ³•è¯»å–å¸§ï¼Œå¯èƒ½æ˜¯è§†é¢‘ç»“æŸ")
                    break
                
                self.stats.total_frames += 1
                
                # å°†å¸§æ”¾å…¥å¤„ç†é˜Ÿåˆ—
                if not self.frame_queue.full():
                    self.frame_queue.put((frame.copy(), time.time()))
                else:
                    self.stats.dropped_frames += 1
                
                # æ˜¾ç¤ºç»“æœ
                if display_results:
                    current_time = time.time()
                    if current_time - last_display_time >= display_interval:
                        self._display_results(frame)
                        last_display_time = current_time
                
                # æ£€æŸ¥é€€å‡ºæ¡ä»¶
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    logger.info("ç”¨æˆ·è¯·æ±‚é€€å‡º")
                    break
            
            # æ¸…ç†èµ„æº
            cap.release()
            if display_results:
                cv2.destroyAllWindows()
            
            self.stop_analysis()
            return True
            
        except Exception as e:
            logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            self.stop_analysis()
            return False
    
    def _display_results(self, frame: np.ndarray):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        try:
            # è·å–æœ€æ–°çš„åˆ†æç»“æœ
            if not self.result_queue.empty():
                result = self.result_queue.get()
                
                # åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                display_frame = frame.copy()
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†
                for detection in result.detections:
                    bbox = detection['bbox']
                    class_name = detection['class_name']
                    confidence = detection['confidence']
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(display_frame, 
                                (int(bbox[0]), int(bbox[1])), 
                                (int(bbox[2]), int(bbox[3])), 
                                (0, 255, 0), 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾
                    label = f"{class_name}: {confidence:.2f}"
                    if 'distance_m' in detection and detection['distance_m'] is not None:
                        label += f" ({detection['distance_m']:.1f}m)"
                    
                    cv2.putText(display_frame, label,
                              (int(bbox[0]), int(bbox[1]) - 10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºå†³ç­–ä¿¡æ¯
                if result.decision_output:
                    decision_info = [
                        f"Action: {result.decision_output.get('action', 'N/A')}",
                        f"Priority: {result.decision_output.get('priority', 0)}",
                        f"Objects: {result.decision_output.get('statistics', {}).get('total_objects', 0)}",
                        f"Hazards: {result.decision_output.get('statistics', {}).get('high_risk_objects', 0)}"
                    ]
                    
                    for i, info in enumerate(decision_info):
                        cv2.putText(display_frame, info,
                                  (10, 30 + i * 25),
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºå¯¼èˆªä¿¡æ¯
                if getattr(result, 'navigation_output', None):
                    nav = result.navigation_output
                    nav_lines = []
                    if nav.get('instruction'):
                        nav_lines.append(f"Nav: {nav['instruction']}")
                    nav_lines.append(f"NavMode: {nav.get('mode', '')}, State: {nav.get('state', '')}")
                    dist = nav.get('distance_to_destination')
                    if dist is not None:
                        dist_str = f"{dist/1000:.1f}km" if dist > 1000 else f"{dist:.0f}m"
                        nav_lines.append(f"ToDest: {dist_str}")
                    for i, info in enumerate(nav_lines):
                        cv2.putText(display_frame, info,
                                  (10, display_frame.shape[0] - 10 - i * 25),
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 200, 255), 2)
                
                # æ˜¾ç¤ºæ€§èƒ½ä¿¡æ¯
                self._update_stats()
                perf_info = [
                    f"FPS: {self.stats.average_fps:.1f}",
                    f"Processing: {self.stats.average_processing_time*1000:.1f}ms",
                    f"Frames: {self.stats.processed_frames}/{self.stats.total_frames}",
                    f"Dropped: {self.stats.dropped_frames}"
                ]
                
                for i, info in enumerate(perf_info):
                    cv2.putText(display_frame, info,
                              (display_frame.shape[1] - 200, 30 + i * 25),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
                
                cv2.imshow('BlindStar Real-time Analysis', display_frame)
            else:
                # æ²¡æœ‰ç»“æœæ—¶æ˜¾ç¤ºåŸå§‹å¸§
                cv2.imshow('BlindStar Real-time Analysis', frame)
                
        except Exception as e:
            logger.warning(f"æ˜¾ç¤ºç»“æœæ—¶å‡ºé”™: {e}")
    
    def stop_analysis(self):
        """åœæ­¢åˆ†æ"""
        self.is_running = False
        
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=2.0)
        
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.frame_queue.empty():
            try:
                self.frame_queue.get_nowait()
            except queue.Empty:
                break
        
        while not self.result_queue.empty():
            try:
                self.result_queue.get_nowait()
            except queue.Empty:
                break
        
        logger.info("âœ… å®æ—¶åˆ†æå·²åœæ­¢")
    
    def update_gps_location(self, latitude: float, longitude: float,
                            altitude: Optional[float] = None,
                            accuracy: Optional[float] = None) -> bool:
        """æ›´æ–°GPSä½ç½®(å¯¼èˆªå¯ç”¨æ—¶å¯ç”¨)"""
        if not (self.enable_navigation and self.nav_context):
            return False
        location = GPSLocation(latitude=latitude, longitude=longitude,
                               altitude=altitude, accuracy=accuracy)
        return self.nav_context.update_location(location)
    
    def set_navigation_destination(self, latitude: float, longitude: float,
                                   altitude: Optional[float] = None,
                                   accuracy: Optional[float] = None) -> bool:
        """è®¾ç½®å¯¼èˆªç›®çš„åœ°(å¯¼èˆªå¯ç”¨æ—¶å¯ç”¨)"""
        if not (self.enable_navigation and self.nav_context):
            return False
        destination = GPSLocation(latitude=latitude, longitude=longitude,
                                  altitude=altitude, accuracy=accuracy)
        return self.nav_context.set_destination(destination)
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        self._update_stats()
        return {
            "total_frames": self.stats.total_frames,
            "processed_frames": self.stats.processed_frames,
            "dropped_frames": self.stats.dropped_frames,
            "drop_rate": self.stats.dropped_frames / max(1, self.stats.total_frames),
            "average_fps": self.stats.average_fps,
            "average_processing_time": self.stats.average_processing_time,
            "detection_count": self.stats.detection_count,
            "hazard_count": self.stats.hazard_count,
            "decision_count": self.stats.decision_count
        }
    
    def update_parameters(self, **kwargs):
        """æ›´æ–°åˆ†æå‚æ•°"""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
                logger.info(f"å‚æ•°å·²æ›´æ–°: {key} = {value}")
            
            # æ›´æ–°å­ç»„ä»¶å‚æ•°
            if key == "confidence_threshold" and self.detector:
                self.detector.confidence_threshold = value
            elif key.startswith("depth_") and self.decision_engine:
                self.decision_engine.update_risk_parameters(**{key: value})
            elif key == "enable_navigation":
                # å¯ç”¨æˆ–å…³é—­å¯¼èˆªä¸Šä¸‹æ–‡
                if bool(value) and not self.nav_context:
                    try:
                        mode_map = {
                            "assist": NavigationMode.ASSIST,
                            "guide": NavigationMode.GUIDE,
                            "full": NavigationMode.FULL,
                        }
                        mode_enum = mode_map.get((self.nav_mode or "assist").lower(), NavigationMode.ASSIST)
                        self.nav_context = NavigationContextManager(mode=mode_enum)
                        logger.info(f"å¯¼èˆªä¸Šä¸‹æ–‡å·²å¯ç”¨: æ¨¡å¼ {mode_enum.value}")
                    except Exception as e:
                        logger.warning(f"å¯¼èˆªä¸Šä¸‹æ–‡å¯ç”¨å¤±è´¥: {e}")
                        self.enable_navigation = False
                elif not bool(value):
                    self.nav_context = None
                    logger.info("å¯¼èˆªä¸Šä¸‹æ–‡å·²å…³é—­")
            elif key == "nav_mode":
                # åŠ¨æ€åˆ‡æ¢å¯¼èˆªæ¨¡å¼
                try:
                    mode_map = {
                        "assist": NavigationMode.ASSIST,
                        "guide": NavigationMode.GUIDE,
                        "full": NavigationMode.FULL,
                    }
                    mode_enum = mode_map.get((str(value) or "assist").lower(), NavigationMode.ASSIST)
                    if self.nav_context:
                        self.nav_context.context.navigation_mode = mode_enum
                        logger.info(f"å¯¼èˆªæ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode_enum.value}")
                except Exception as e:
                    logger.debug(f"åˆ‡æ¢å¯¼èˆªæ¨¡å¼å¤±è´¥: {e}")
            elif key == "nav_tts_interval":
                try:
                    self._nav_tts_interval = float(value)
                    logger.info(f"å¯¼èˆªTTSæ’­æŠ¥é—´éš”å·²æ›´æ–°ä¸º: {self._nav_tts_interval}s")
                except Exception:
                    logger.warning("æ— æ•ˆçš„ nav_tts_interval å€¼")


# ä¾¿æ·å‡½æ•°
def analyze_video_realtime(source: str = "0", 
                          yolo_model: str = "small",
                          enable_depth: bool = True,
                          enable_tts: bool = True,
                          max_fps: float = 15.0,
                          enable_navigation: bool = False,
                          nav_mode: str = "assist") -> bool:
    """
    ä¾¿æ·å‡½æ•°ï¼šå¯åŠ¨å®æ—¶è§†é¢‘åˆ†æ
    
    Args:
        source: è§†é¢‘æº
        yolo_model: YOLOæ¨¡å‹å¤§å°
        enable_depth: æ˜¯å¦å¯ç”¨æ·±åº¦ä¼°è®¡
        enable_tts: æ˜¯å¦å¯ç”¨è¯­éŸ³æ’­æŠ¥
        max_fps: æœ€å¤§å¤„ç†å¸§ç‡
        
    Returns:
        æ˜¯å¦æˆåŠŸå®Œæˆåˆ†æ
    """
    analyzer = RealtimeVideoAnalyzer(
        yolo_model=yolo_model,
        enable_depth=enable_depth,
        enable_tts=enable_tts,
        max_fps=max_fps,
        enable_navigation=enable_navigation,
        nav_mode=nav_mode
    )
    
    try:
        return analyzer.start_analysis(source, display_results=True)
    finally:
        stats = analyzer.get_statistics()
        logger.info(f"åˆ†æå®Œæˆç»Ÿè®¡: {stats}")
        return True
