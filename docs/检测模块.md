# BlindStar æ£€æµ‹æ¨¡å—æ–‡æ¡£

## ğŸ“– æ¨¡å—æ¦‚è¿°

BlindStaræ£€æµ‹æ¨¡å—æ˜¯ç³»ç»Ÿçš„è§†è§‰æ„ŸçŸ¥æ ¸å¿ƒï¼ŒåŸºäºYOLOç³»åˆ—æ¨¡å‹æä¾›é«˜ç²¾åº¦çš„å®æ—¶ç‰©ä½“æ£€æµ‹èƒ½åŠ›ã€‚æ”¯æŒYOLO11å’ŒYOLOv8æ¨¡å‹ï¼Œèƒ½å¤Ÿè¯†åˆ«80ç§COCOç±»åˆ«ç‰©ä½“ï¼Œä¸ºè§†éšœç”¨æˆ·æä¾›å‡†ç¡®çš„ç¯å¢ƒæ„ŸçŸ¥ä¿¡æ¯ã€‚

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶
- **æ£€æµ‹å™¨** (`core/detector.py`): æ ¸å¿ƒç‰©ä½“æ£€æµ‹å¼•æ“
- **å¸§åˆ†æå™¨** (`core/frame_analyzer.py`): å¸§çº§åˆ«çš„ç»¼åˆåˆ†æ
- **å®æ—¶è§†é¢‘åˆ†æå™¨** (`core/realtime_video_analyzer.py`): å®æ—¶è§†é¢‘æµå¤„ç†
- **æ‰¹é‡å¤„ç†å™¨** (`core/batch_processor.py`): æ‰¹é‡è§†é¢‘/å›¾åƒå¤„ç†
- **è‡ªå®šä¹‰è®­ç»ƒæ¨¡å‹**: é’ˆå¯¹è§†éšœè¾…åŠ©åœºæ™¯ä¼˜åŒ–çš„ä¸“ç”¨æ¨¡å‹

### æŠ€æœ¯æ ˆ
- **YOLO11/YOLOv8**: æœ€æ–°çš„å®æ—¶ç‰©ä½“æ£€æµ‹æ¨¡å‹
- **Ultralytics**: ç»Ÿä¸€çš„YOLOæ¨¡å‹è®­ç»ƒå’Œæ¨ç†æ¡†æ¶
- **PyTorch**: æ·±åº¦å­¦ä¹ æ¨ç†å¼•æ“
- **OpenCV**: å›¾åƒå¤„ç†å’Œè§†é¢‘I/O
- **CUDA**: GPUåŠ é€Ÿæ¨ç†

## ğŸ¯ ç‰©ä½“æ£€æµ‹å¼•æ“

### Detectorç±»
æ ¸å¿ƒæ£€æµ‹ç»„ä»¶ï¼Œæ”¯æŒå¤šç§YOLOæ¨¡å‹ï¼š

```python
class Detector:
    def __init__(self, model_path="yolo11n.pt", device="auto"):
        self.model_path = model_path
        self.device = device
        self.model = None
        self.class_names = []
        self.confidence_threshold = 0.5
        self.iou_threshold = 0.45
```

### æ”¯æŒçš„æ¨¡å‹ç±»å‹
- **YOLO11ç³»åˆ—**: yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt
- **YOLOv8ç³»åˆ—**: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt
- **è‡ªå®šä¹‰æ¨¡å‹**: åŸºäºBlindStaræ•°æ®é›†è®­ç»ƒçš„ä¸“ç”¨æ¨¡å‹

### æ£€æµ‹åŠŸèƒ½

#### 1. åŸºç¡€ç‰©ä½“æ£€æµ‹
```python
def detect_objects(self, image, confidence=0.5):
    """æ£€æµ‹å›¾åƒä¸­çš„ç‰©ä½“"""
    results = self.model(image, conf=confidence)
    detections = []
    
    for result in results:
        boxes = result.boxes
        if boxes is not None:
            for box in boxes:
                detection = {
                    'bbox': box.xyxy[0].cpu().numpy(),
                    'confidence': box.conf[0].cpu().numpy(),
                    'class_id': int(box.cls[0].cpu().numpy()),
                    'class_name': self.class_names[int(box.cls[0])]
                }
                detections.append(detection)
    
    return detections
```

#### 2. æ‰¹é‡æ£€æµ‹
```python
def detect_batch(self, images, confidence=0.5):
    """æ‰¹é‡æ£€æµ‹å¤šå¼ å›¾åƒ"""
    results = self.model(images, conf=confidence)
    batch_detections = []
    
    for result in results:
        # å¤„ç†æ¯å¼ å›¾åƒçš„æ£€æµ‹ç»“æœ
        detections = self.process_single_result(result)
        batch_detections.append(detections)
    
    return batch_detections
```

## ğŸ¥ å®æ—¶è§†é¢‘åˆ†æ

### RealtimeVideoAnalyzerç±»
å®æ—¶è§†é¢‘æµå¤„ç†å’Œåˆ†æï¼š

```python
class RealtimeVideoAnalyzer:
    def __init__(self, detector, distance_calculator):
        self.detector = detector
        self.distance_calculator = distance_calculator
        self.frame_queue = queue.Queue(maxsize=10)
        self.result_queue = queue.Queue(maxsize=10)
        self.is_running = False
```

### å®æ—¶å¤„ç†æµç¨‹
1. **è§†é¢‘æ•è·**: ä»æ‘„åƒå¤´æˆ–è§†é¢‘æ–‡ä»¶è·å–å¸§
2. **é¢„å¤„ç†**: å›¾åƒå°ºå¯¸è°ƒæ•´å’Œæ ¼å¼è½¬æ¢
3. **ç‰©ä½“æ£€æµ‹**: YOLOæ¨¡å‹æ¨ç†
4. **æ·±åº¦ä¼°è®¡**: è·ç¦»è®¡ç®—å’Œæ·±åº¦åˆ†æ
5. **ç»“æœèåˆ**: æ£€æµ‹ç»“æœä¸æ·±åº¦ä¿¡æ¯ç»“åˆ
6. **åå¤„ç†**: ç»“æœè¿‡æ»¤å’Œä¼˜åŒ–

### æ€§èƒ½ä¼˜åŒ–
- **å¤šçº¿ç¨‹å¤„ç†**: åˆ†ç¦»æ•è·ã€æ£€æµ‹å’Œæ˜¾ç¤ºçº¿ç¨‹
- **å¸§è·³è·ƒ**: æ ¹æ®å¤„ç†èƒ½åŠ›åŠ¨æ€è°ƒæ•´å¸§ç‡
- **æ‰¹é‡æ¨ç†**: å¤šå¸§æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
- **å†…å­˜ç®¡ç†**: æ™ºèƒ½ç¼“å­˜å’Œå†…å­˜å›æ”¶

## ğŸ“Š å¸§åˆ†æå™¨

### FrameAnalyzerç±»
å•å¸§çš„ç»¼åˆåˆ†æå’Œå¤„ç†ï¼š

```python
class FrameAnalyzer:
    def __init__(self, detector, distance_calc, risk_assessor):
        self.detector = detector
        self.distance_calc = distance_calc
        self.risk_assessor = risk_assessor
        self.analysis_history = []
```

### åˆ†æç»´åº¦

#### 1. ç‰©ä½“æ£€æµ‹åˆ†æ
```python
def analyze_detections(self, detections):
    """åˆ†ææ£€æµ‹ç»“æœ"""
    analysis = {
        'total_objects': len(detections),
        'object_categories': {},
        'high_confidence_objects': [],
        'potential_risks': []
    }
    
    for detection in detections:
        category = detection['class_name']
        analysis['object_categories'][category] = \
            analysis['object_categories'].get(category, 0) + 1
            
        if detection['confidence'] > 0.8:
            analysis['high_confidence_objects'].append(detection)
    
    return analysis
```

#### 2. ç©ºé—´åˆ†å¸ƒåˆ†æ
```python
def analyze_spatial_distribution(self, detections, image_shape):
    """åˆ†æç‰©ä½“ç©ºé—´åˆ†å¸ƒ"""
    height, width = image_shape[:2]
    
    # å°†å›¾åƒåˆ†ä¸º9ä¸ªåŒºåŸŸ
    regions = {
        'top_left': [], 'top_center': [], 'top_right': [],
        'middle_left': [], 'middle_center': [], 'middle_right': [],
        'bottom_left': [], 'bottom_center': [], 'bottom_right': []
    }
    
    for detection in detections:
        region = self.get_object_region(detection['bbox'], width, height)
        regions[region].append(detection)
    
    return regions
```

#### 3. è¿åŠ¨åˆ†æ
```python
def analyze_motion(self, current_detections, previous_detections):
    """åˆ†æç‰©ä½“è¿åŠ¨"""
    motion_analysis = {
        'moving_objects': [],
        'stationary_objects': [],
        'new_objects': [],
        'disappeared_objects': []
    }
    
    # ç‰©ä½“å…³è”å’Œè¿åŠ¨è®¡ç®—
    associations = self.associate_detections(
        current_detections, previous_detections
    )
    
    for current, previous in associations:
        motion = self.calculate_motion(current, previous)
        if motion['speed'] > 0.5:  # 0.5 m/s é˜ˆå€¼
            motion_analysis['moving_objects'].append({
                'detection': current,
                'motion': motion
            })
        else:
            motion_analysis['stationary_objects'].append(current)
    
    return motion_analysis
```

## ğŸ·ï¸ æ”¯æŒçš„æ£€æµ‹ç±»åˆ«

### COCO-80ç±»åˆ«
BlindStaræ”¯æŒå®Œæ•´çš„COCOæ•°æ®é›†80ä¸ªç±»åˆ«ï¼š

#### äººå‘˜ç±»åˆ«
```
- person (äººå‘˜)
```

#### è½¦è¾†ç±»åˆ«
```
- car (æ±½è½¦)
- truck (å¡è½¦) 
- bus (å…¬äº¤è½¦)
- motorcycle (æ‘©æ‰˜è½¦)
- bicycle (è‡ªè¡Œè½¦)
```

#### äº¤é€šè®¾æ–½
```
- traffic light (äº¤é€šç¯)
- stop sign (åœè½¦æ ‡å¿—)
```

#### åŠ¨ç‰©ç±»åˆ«
```
- bird (é¸Ÿç±»)
- cat (çŒ«)
- dog (ç‹—)
- horse (é©¬)
- sheep (ç¾Š)
- cow (ç‰›)
- elephant (å¤§è±¡)
- bear (ç†Š)
- zebra (æ–‘é©¬)
- giraffe (é•¿é¢ˆé¹¿)
```

#### æ—¥å¸¸ç‰©å“
```
- backpack (èƒŒåŒ…)
- umbrella (é›¨ä¼)
- handbag (æ‰‹æåŒ…)
- tie (é¢†å¸¦)
- suitcase (è¡Œæç®±)
- chair (æ¤…å­)
- couch (æ²™å‘)
- bed (åºŠ)
- dining table (é¤æ¡Œ)
- toilet (é©¬æ¡¶)
```

### è‡ªå®šä¹‰ç±»åˆ«æ‰©å±•
é’ˆå¯¹è§†éšœè¾…åŠ©åœºæ™¯çš„ä¸“ç”¨ç±»åˆ«ï¼š

```python
BLINDSTAR_CUSTOM_CLASSES = {
    'crosswalk': 'äººè¡Œæ¨ªé“',
    'stairs': 'æ¥¼æ¢¯', 
    'curb': 'è·¯ç¼˜',
    'railing': 'æ æ†',
    'guide_arrows': 'å¯¼å‘ç®­å¤´',
    'red_light': 'çº¢ç¯',
    'green_light': 'ç»¿ç¯',
    'snow': 'ç§¯é›ª',
    'water': 'ç§¯æ°´'
}
```

## âš™ï¸ é…ç½®å‚æ•°

### æ£€æµ‹æ¨¡å‹é…ç½®
```python
DETECTION_CONFIG = {
    'model_path': 'models/yolo11s.pt',      # æ¨¡å‹è·¯å¾„
    'device': 'cuda:0',                     # è®¾å¤‡é€‰æ‹©
    'confidence_threshold': 0.5,            # ç½®ä¿¡åº¦é˜ˆå€¼
    'iou_threshold': 0.45,                  # NMS IoUé˜ˆå€¼
    'max_detections': 100,                  # æœ€å¤§æ£€æµ‹æ•°é‡
    'input_size': 640,                      # è¾“å…¥å›¾åƒå°ºå¯¸
    'half_precision': True,                 # åŠç²¾åº¦æ¨ç†
    'batch_size': 1                         # æ‰¹å¤„ç†å¤§å°
}
```

### å®æ—¶å¤„ç†é…ç½®
```python
REALTIME_CONFIG = {
    'target_fps': 30,                       # ç›®æ ‡å¸§ç‡
    'max_queue_size': 10,                   # æœ€å¤§é˜Ÿåˆ—å¤§å°
    'skip_frames': 0,                       # è·³å¸§æ•°é‡
    'enable_threading': True,               # å¯ç”¨å¤šçº¿ç¨‹
    'buffer_size': 3,                       # ç¼“å†²åŒºå¤§å°
    'timeout': 5.0                          # å¤„ç†è¶…æ—¶æ—¶é—´
}
```

### ç±»åˆ«è¿‡æ»¤é…ç½®
```python
CLASS_FILTER_CONFIG = {
    'enabled_classes': [                    # å¯ç”¨çš„ç±»åˆ«
        'person', 'car', 'truck', 'bus', 
        'motorcycle', 'bicycle', 'traffic light'
    ],
    'priority_classes': [                   # ä¼˜å…ˆçº§ç±»åˆ«
        'person', 'car', 'traffic light'
    ],
    'ignore_classes': [                     # å¿½ç•¥çš„ç±»åˆ«
        'remote', 'keyboard', 'mouse'
    ],
    'confidence_by_class': {                # æŒ‰ç±»åˆ«è®¾ç½®ç½®ä¿¡åº¦
        'person': 0.3,
        'car': 0.5,
        'traffic light': 0.7
    }
}
```

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬æ£€æµ‹ä½¿ç”¨
```python
from core.detector import Detector

# åˆå§‹åŒ–æ£€æµ‹å™¨
detector = Detector(model_path="yolo11s.pt", device="cuda")

# åŠ è½½å›¾åƒ
image = cv2.imread("test_image.jpg")

# æ‰§è¡Œæ£€æµ‹
detections = detector.detect_objects(image, confidence=0.5)

# å¤„ç†ç»“æœ
for detection in detections:
    print(f"æ£€æµ‹åˆ°: {detection['class_name']}, "
          f"ç½®ä¿¡åº¦: {detection['confidence']:.2f}")
```

### å®æ—¶è§†é¢‘æ£€æµ‹
```python
from core.realtime_video_analyzer import RealtimeVideoAnalyzer
from core.detector import Detector
from core.distance import DistanceCalculator

# åˆå§‹åŒ–ç»„ä»¶
detector = Detector("yolo11s.pt")
distance_calc = DistanceCalculator()
analyzer = RealtimeVideoAnalyzer(detector, distance_calc)

# å¼€å§‹å®æ—¶åˆ†æ
analyzer.start_analysis(source=0)  # ä½¿ç”¨æ‘„åƒå¤´

# è·å–ç»“æœ
while analyzer.is_running:
    result = analyzer.get_latest_result()
    if result:
        print(f"æ£€æµ‹åˆ° {len(result['detections'])} ä¸ªç‰©ä½“")
```

### æ‰¹é‡å¤„ç†
```python
from core.batch_processor import BatchProcessor

# åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨
processor = BatchProcessor(detector)

# å¤„ç†è§†é¢‘æ–‡ä»¶
results = processor.process_video(
    input_path="input_video.mp4",
    output_path="output_video.mp4",
    save_analysis=True
)

print(f"å¤„ç†å®Œæˆï¼Œå…±åˆ†æ {results['total_frames']} å¸§")
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æ£€æµ‹ç²¾åº¦ä½
```
åŸå› : æ¨¡å‹ä¸é€‚åˆå½“å‰åœºæ™¯æˆ–ç½®ä¿¡åº¦é˜ˆå€¼ä¸å½“
è§£å†³:
- ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹(å¦‚yolo11l.pt)
- è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
- ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒæ¨¡å‹
- æ”¹å–„å…‰ç…§æ¡ä»¶
```

#### 2. æ£€æµ‹é€Ÿåº¦æ…¢
```
åŸå› : ç¡¬ä»¶æ€§èƒ½ä¸è¶³æˆ–é…ç½®ä¸å½“
è§£å†³:
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹(å¦‚yolo11n.pt)
- å¯ç”¨åŠç²¾åº¦æ¨ç†
- è°ƒæ•´è¾“å…¥å›¾åƒå°ºå¯¸
- ä½¿ç”¨GPUåŠ é€Ÿ
```

#### 3. å†…å­˜å ç”¨è¿‡é«˜
```
åŸå› : æ‰¹å¤„ç†å¤§å°è¿‡å¤§æˆ–ç¼“å­˜è®¾ç½®ä¸å½“
è§£å†³:
- å‡å°batch_size
- è°ƒæ•´é˜Ÿåˆ—å¤§å°
- å¯ç”¨å†…å­˜å›æ”¶
- ä½¿ç”¨è¾ƒå°çš„è¾“å…¥å°ºå¯¸
```

### è°ƒè¯•å‘½ä»¤
```bash
# æµ‹è¯•æ£€æµ‹å™¨
python -m core.detector --test-image test.jpg

# æµ‹è¯•å®æ—¶æ£€æµ‹
python -m core.realtime_video_analyzer --source 0

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python -m core.detector --benchmark --model yolo11s.pt
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### æ£€æµ‹ç²¾åº¦ (COCOæ•°æ®é›†)
- **YOLO11n**: mAP50: 39.5%, mAP50-95: 26.4%
- **YOLO11s**: mAP50: 47.0%, mAP50-95: 32.1%
- **YOLO11m**: mAP50: 51.5%, mAP50-95: 36.6%
- **YOLO11l**: mAP50: 53.2%, mAP50-95: 38.3%

### æ¨ç†é€Ÿåº¦ (RTX 5060 Laptop)
- **YOLO11n**: ~120 FPS
- **YOLO11s**: ~80 FPS  
- **YOLO11m**: ~50 FPS
- **YOLO11l**: ~30 FPS

### è‡ªå®šä¹‰æ¨¡å‹æ€§èƒ½
- **æ€»ä½“mAP50**: 0.637
- **ä¼˜ç§€ç±»åˆ«**: red_light (0.979), crosswalk (0.975), green_light (0.968)
- **å¾…æ”¹è¿›ç±»åˆ«**: railing (0.155), curb (0.18), snow (0.282)

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v1.3 (å½“å‰ç‰ˆæœ¬)
- âœ… é›†æˆYOLO11æœ€æ–°æ¨¡å‹
- âœ… å®Œæˆè‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒ(50è½®ï¼ŒmAP50: 0.637)
- âœ… ä¼˜åŒ–å®æ—¶æ£€æµ‹æ€§èƒ½
- âœ… æ·»åŠ æ‰¹é‡å¤„ç†åŠŸèƒ½

### v1.2
- âœ… æ”¯æŒYOLOv8ç³»åˆ—æ¨¡å‹
- âœ… å®ç°å¤šçº¿ç¨‹å®æ—¶å¤„ç†
- âœ… æ·»åŠ ç±»åˆ«è¿‡æ»¤åŠŸèƒ½

### v1.1
- âœ… åŸºç¡€YOLOæ£€æµ‹åŠŸèƒ½
- âœ… ç®€å•çš„ç»“æœå¯è§†åŒ–
- âœ… åŸºæœ¬çš„é…ç½®ç®¡ç†

## ğŸ“š ç›¸å…³æ–‡æ¡£
- [æ·±åº¦ä¼°è®¡æ¨¡å—æ–‡æ¡£](./æ·±åº¦ä¼°è®¡æ¨¡å—.md)
- [é¿éšœæ¨¡å—æ–‡æ¡£](./é¿éšœæ¨¡å—.md)
- [è¯­éŸ³æ¨¡å—æ–‡æ¡£](./è¯­éŸ³æ¨¡å—.md)
- [æ¨¡å‹è®­ç»ƒæŒ‡å—](./DEPTH_ANNOTATION_GUIDE.md)
